{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf107df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fixed chartPath fields to web paths.\n",
      "üõü Backup at: /Users/ousmane/Desktop/2025 - Documentations/Python/3 Economics/genesis-research/app/data/insights.json.bak-chartpaths\n",
      "üíæ Updated:   /Users/ousmane/Desktop/2025 - Documentations/Python/3 Economics/genesis-research/app/data/insights.json\n"
     ]
    }
   ],
   "source": [
    "# fix_chart_paths.py ‚Äî run from anywhere\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json, re\n",
    "\n",
    "INSIGHTS = Path(\"/Users/ousmane/Desktop/2025 - Documentations/Python/3 Economics/genesis-research/app/data/insights.json\")\n",
    "\n",
    "data = json.loads(INSIGHTS.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "def to_web_path(chart_path: str) -> str:\n",
    "    if not chart_path:\n",
    "        return chart_path\n",
    "    # If it already starts with /charts/, keep it\n",
    "    if chart_path.startswith(\"/charts/\"):\n",
    "        return chart_path\n",
    "    # If it's an absolute or repo-ish path containing /public/charts/..., convert to /charts/...\n",
    "    m = re.search(r\"/public/(charts/.*)$\", chart_path)\n",
    "    if m:\n",
    "        return \"/\" + m.group(1)\n",
    "    # Also handle cases like \"genesis-research/public/charts/...\"\n",
    "    m = re.search(r\"public/(charts/.*)$\", chart_path)\n",
    "    if m:\n",
    "        return \"/\" + m.group(1)\n",
    "    # Fallback: if it ends with charts/... assume that is the tail\n",
    "    m = re.search(r\"(charts/.*)$\", chart_path)\n",
    "    if m:\n",
    "        return \"/\" + m.group(1)\n",
    "    # otherwise leave as-is\n",
    "    return chart_path\n",
    "\n",
    "for ins in data:\n",
    "    cp = ins.get(\"chartPath\",\"\")\n",
    "    fixed = to_web_path(cp)\n",
    "    if fixed != cp:\n",
    "        ins[\"chartPath\"] = fixed\n",
    "\n",
    "# sort by date ASC and re-id\n",
    "def key(ins):\n",
    "    try:\n",
    "        return datetime.strptime(ins.get(\"date\",\"01-01-1900\"), \"%d-%m-%Y\")\n",
    "    except Exception:\n",
    "        return datetime(1900,1,1)\n",
    "\n",
    "data.sort(key=key)\n",
    "for i, ins in enumerate(data, 1):\n",
    "    ins[\"id\"] = i\n",
    "\n",
    "# backup + write\n",
    "backup = INSIGHTS.with_suffix(\".json.bak-chartpaths\")\n",
    "backup.write_text(INSIGHTS.read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n",
    "INSIGHTS.write_text(json.dumps(data, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "print(\"‚úÖ Fixed chartPath fields to web paths.\")\n",
    "print(f\"üõü Backup at: {backup}\")\n",
    "print(f\"üíæ Updated:   {INSIGHTS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3d0b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Found 15 chart file(s) to check under /Users/ousmane/Desktop/2025 - Documentations/Python/3 Economics/genesis-research/public/charts\n",
      "üõ†Ô∏è Planned renames: 15\n",
      "   - public/charts/Commodities/Gold Miners: From Capitulation to Conviction_2025-09-30.svg  ‚Üí  public/charts/Commodities/gold-miners-from-capitulation-to-conviction_2025-09-30.svg\n",
      "   - public/charts/Commodities/Gold and Geopolitics: From Relief to Resilience_2025-10-11.svg  ‚Üí  public/charts/Commodities/gold-and-geopolitics-from-relief-to-resilience_2025-10-11.svg\n",
      "   - public/charts/Economics/Confidence Slips, Momentum Risks Ahead_2025-10-10.svg  ‚Üí  public/charts/Economics/confidence-slips-momentum-risks-ahead_2025-10-10.svg\n",
      "   - public/charts/Economics/Inflation Psychology: Relief at 1-Year, Steady at 5-Year_2025-10-10.svg  ‚Üí  public/charts/Economics/inflation-psychology-relief-at-1-year-steady-at-5-year_2025-10-10.svg\n",
      "   - public/charts/Economics/Manufacturing Regains Momentum, Inflation Pressures Persist_2025-10-15.svg  ‚Üí  public/charts/Economics/manufacturing-regains-momentum-inflation-pressures-persist_2025-10-15.svg\n",
      "   - public/charts/Economics/Margins Under Pressure_2025-10-01.svg  ‚Üí  public/charts/Economics/margins-under-pressure_2025-10-01.svg\n",
      "   - public/charts/Economics/Philly Fed: Headline Craters, Internals Hold Up_2025-10-16.svg  ‚Üí  public/charts/Economics/philly-fed-headline-craters-internals-hold-up_2025-10-16.svg\n",
      "   - public/charts/Economics/Sticky Prices, Cooling Demand_2025-10-03.svg  ‚Üí  public/charts/Economics/sticky-prices-cooling-demand_2025-10-03.svg\n",
      "   - public/charts/Equities/Bank Fragility Watch ‚Äî Zions Sits on the 61.8%_2025-10-17.svg  ‚Üí  public/charts/Equities/bank-fragility-watch-zions-sits-on-the-61-8_2025-10-17.svg\n",
      "   - public/charts/Equities/Dow Jones Fades the 76.4% Fibonacci_2025-10-15.svg  ‚Üí  public/charts/Equities/dow-jones-fades-the-76-4-fibonacci_2025-10-15.svg\n",
      "   - public/charts/Equities/Technicals Point To a Mild Pull Back vs Leg Down_2025-10-14.svg  ‚Üí  public/charts/Equities/technicals-point-to-a-mild-pull-back-vs-leg-down_2025-10-14.svg\n",
      "   - public/charts/Equities/Trump Shock: Tariff Risk Reprices, Sentiment Partially Rebounds_2025-10-11.svg  ‚Üí  public/charts/Equities/trump-shock-tariff-risk-reprices-sentiment-partially-rebounds_2025-10-11.svg\n",
      "   - public/charts/Fixed Income/10‚ÄëYear Treasury vs DXY: Easing Path & the Insurance Cut_2025-10-09.svg  ‚Üí  public/charts/Fixed Income/10-year-treasury-vs-dxy-easing-path-the-insurance-cut_2025-10-09.svg\n",
      "   - public/charts/Technical/Tactical Update ‚Äî Dow Jones: Partial TP Hit, Market Tests Resilience_2025-10-20.svg  ‚Üí  public/charts/Technical/tactical-update-dow-jones-partial-tp-hit-market-tests-resilience_2025-10-20.svg\n",
      "   - public/charts/Technical/Tactical Update ‚Äî US30: Retesting the 76.4% Fade Amid Renewed Animal Spirits_2025-10-20.svg  ‚Üí  public/charts/Technical/tactical-update-us30-retesting-the-76-4-fade-amid-renewed-animal-spirits_2025-10-20.svg\n",
      "‚úÖ Renames applied.\n",
      "üß© insights.json paths updated: 13 (reformatted: 0)\n",
      "üõü Backup: /Users/ousmane/Desktop/2025 - Documentations/Python/3 Economics/genesis-research/app/data/insights.json.bak-slugify\n",
      "üíæ Updated: /Users/ousmane/Desktop/2025 - Documentations/Python/3 Economics/genesis-research/app/data/insights.json\n",
      "\n",
      "‚úÖ NEXT:\n",
      "1) Set APPLY_CHANGES = True and re-run to apply changes.\n",
      "2) git add -A && git commit -m 'Slugify charts + update insights paths' && git pull --rebase && git push\n",
      "3) Redeploy; filenames are now ASCII-hyphen and paths are web-safe.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Slugify all chart filenames under public/charts and update app/data/insights.json.\n",
    "- Converts filenames to safe ASCII hyphen slugs: \"<slug-title>_YYYY-MM-DD.svg\"\n",
    "- Fixes spaces/Unicode/dashes/quotes, normalizes dates (YYYY-MM-DD)\n",
    "- Resolves naming collisions with -v2, -v3, ...\n",
    "- Updates insights.json chartPath to \"/charts/<Category>/<new_filename>.svg\"\n",
    "- Repairs any bad paths (absolute local or repo paths) to web paths\n",
    "- Creates a timestamped backup of insights.json\n",
    "- Uses `git mv` when available (falls back to os.rename)\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json, re, unicodedata, subprocess, shutil, sys\n",
    "\n",
    "# === CONFIG ===\n",
    "BASE_DIR = Path(\"/Users/ousmane/Desktop/2025 - Documentations/Python/3 Economics/genesis-research\")\n",
    "CHARTS_ROOT = BASE_DIR / \"public\" / \"charts\"\n",
    "INSIGHTS_JSON = BASE_DIR / \"app\" / \"data\" / \"insights.json\"\n",
    "\n",
    "# Set to True to actually rename files and write insights.json\n",
    "APPLY_CHANGES = True  # <-- change to True when you're ready\n",
    "\n",
    "# Colors (not modified here, only used for sanity if needed)\n",
    "CATEGORY_FOLDERS = [\"Equities\",\"Economics\",\"Technical\",\"Commodities\",\"Fixed Income\",\"Currencies\",\"Cross Assets\",\"Education\"]\n",
    "\n",
    "# === Helpers ===\n",
    "\n",
    "DASH_MAP = {\"\\u2010\":\"-\",\"\\u2011\":\"-\",\"\\u2012\":\"-\",\"\\u2013\":\"-\",\"\\u2014\":\"-\",\"\\u2212\":\"-\"}\n",
    "QUOTE_MAP = {\"\\u2018\":\"'\", \"\\u2019\":\"'\", \"\\u201C\":'\"', \"\\u201D\":'\"'}\n",
    "SPACE_RE = re.compile(r\"\\s+\")\n",
    "NON_ALNUM_RE = re.compile(r\"[^a-z0-9]+\")\n",
    "\n",
    "def nfkd(s: str) -> str:\n",
    "    return unicodedata.normalize(\"NFKD\", s or \"\")\n",
    "\n",
    "def ascii_strip(s: str) -> str:\n",
    "    # NFKD then drop accents\n",
    "    return \"\".join(c for c in nfkd(s) if not unicodedata.combining(c))\n",
    "\n",
    "def tidy_text(s: str) -> str:\n",
    "    s = ascii_strip(s)\n",
    "    for k,v in {**DASH_MAP, **QUOTE_MAP}.items():\n",
    "        s = s.replace(k, v)\n",
    "    s = SPACE_RE.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def slugify_title(title: str) -> str:\n",
    "    t = tidy_text(title).lower()\n",
    "    t = NON_ALNUM_RE.sub(\"-\", t)\n",
    "    t = re.sub(r\"-{2,}\", \"-\", t).strip(\"-\")\n",
    "    return t or \"chart\"\n",
    "\n",
    "def normalize_date_in_stem(stem: str) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Try to split 'Title_YYYY-MM-DD' or 'Title_YYYY_MM_DD' -> (Title, YYYY-MM-DD)\n",
    "    If no date detected, returns (stem, None)\n",
    "    \"\"\"\n",
    "    m = re.match(r\"^(.*)_([0-9]{4})[-_]?([0-9]{2})[-_]?([0-9]{2})$\", stem)\n",
    "    if not m:\n",
    "        return stem, None\n",
    "    title_part = m.group(1).strip()\n",
    "    yyyy, mm, dd = m.group(2), m.group(3), m.group(4)\n",
    "    try:\n",
    "        dt = datetime(int(yyyy), int(mm), int(dd))\n",
    "        return title_part, dt.strftime(\"%Y-%m-%d\")\n",
    "    except Exception:\n",
    "        return title_part, None\n",
    "\n",
    "def find_category_for_path(path: Path) -> str | None:\n",
    "    try:\n",
    "        rel = path.relative_to(CHARTS_ROOT)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    if rel.parts:\n",
    "        cat = rel.parts[0]\n",
    "        return cat if cat in CATEGORY_FOLDERS else None\n",
    "    return None\n",
    "\n",
    "def web_path(category: str, filename: str) -> str:\n",
    "    return f\"/charts/{category}/{filename}\"\n",
    "\n",
    "def run_git_mv(src: Path, dst: Path) -> bool:\n",
    "    \"\"\"Use `git mv -f` if available, return True if succeeded.\"\"\"\n",
    "    try:\n",
    "        subprocess.run([\"git\", \"--version\"], cwd=BASE_DIR, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
    "        subprocess.run([\"git\", \"mv\", \"-f\", str(src), str(dst)], cwd=BASE_DIR, check=True)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def safe_rename(src: Path, dst: Path):\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    # handle case-insensitive FS weirdness: if names differ only by case/punct, do temp hop\n",
    "    if src.resolve() == dst.resolve():\n",
    "        return\n",
    "    try_git = run_git_mv(src, dst)\n",
    "    if not try_git:\n",
    "        dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "        src.rename(dst)\n",
    "\n",
    "# === Scan and plan renames ===\n",
    "\n",
    "if not CHARTS_ROOT.exists():\n",
    "    sys.exit(f\"Charts root not found: {CHARTS_ROOT}\")\n",
    "if not INSIGHTS_JSON.exists():\n",
    "    sys.exit(f\"insights.json not found: {INSIGHTS_JSON}\")\n",
    "\n",
    "all_svg = sorted(CHARTS_ROOT.rglob(\"*.svg\"))\n",
    "print(f\"üìä Found {len(all_svg)} chart file(s) to check under {CHARTS_ROOT}\")\n",
    "\n",
    "rename_plan = {}  # old_path -> new_path\n",
    "occupied = set()  # set of (category, filename) to avoid collisions\n",
    "\n",
    "for f in all_svg:\n",
    "    category = find_category_for_path(f)\n",
    "    if not category:\n",
    "        # file outside known category; skip\n",
    "        continue\n",
    "    stem = f.stem\n",
    "    title_part, date_part = normalize_date_in_stem(stem)\n",
    "\n",
    "    # If we didn‚Äôt parse a date, we‚Äôll keep the stem slug and leave out the date\n",
    "    slug_title = slugify_title(title_part if title_part else stem)\n",
    "\n",
    "    if date_part:\n",
    "        new_name_base = f\"{slug_title}_{date_part}\"\n",
    "    else:\n",
    "        new_name_base = slug_title  # no date parsed; rare case\n",
    "\n",
    "    # ensure .svg ext\n",
    "    new_name = f\"{new_name_base}.svg\"\n",
    "\n",
    "    # resolve collisions\n",
    "    v = 2\n",
    "    while (category, new_name) in occupied or ((f.parent / new_name) != f and (f.parent / new_name).exists()):\n",
    "        new_name = f\"{new_name_base}-v{v}.svg\"\n",
    "        v += 1\n",
    "\n",
    "    occupied.add((category, new_name))\n",
    "\n",
    "    new_path = f.parent / new_name\n",
    "\n",
    "    # If identical (already slugified), skip; else plan rename\n",
    "    if new_path != f:\n",
    "        rename_plan[f] = new_path\n",
    "\n",
    "print(f\"üõ†Ô∏è Planned renames: {len(rename_plan)}\")\n",
    "for src, dst in list(rename_plan.items())[:20]:\n",
    "    print(f\"   - {src.relative_to(BASE_DIR)}  ‚Üí  {dst.relative_to(BASE_DIR)}\")\n",
    "if len(rename_plan) > 20:\n",
    "    print(f\"   ‚Ä¶ and {len(rename_plan)-20} more\")\n",
    "\n",
    "# === Apply renames ===\n",
    "if APPLY_CHANGES and rename_plan:\n",
    "    for src, dst in rename_plan.items():\n",
    "        safe_rename(src, dst)\n",
    "    print(\"‚úÖ Renames applied.\")\n",
    "else:\n",
    "    if rename_plan:\n",
    "        print(\"‚ÑπÔ∏è Dry-run: set APPLY_CHANGES = True to perform renames.\")\n",
    "\n",
    "# Build a mapping from *old web path* to *new web path* for insights update\n",
    "path_map = {}\n",
    "for old, new in rename_plan.items():\n",
    "    old_cat = find_category_for_path(old)\n",
    "    new_cat = find_category_for_path(new)\n",
    "    if old_cat and new_cat:\n",
    "        path_map[web_path(old_cat, old.name)] = web_path(new_cat, new.name)\n",
    "\n",
    "# Also, create a map from *current filesystem* for already-ok files (no rename)\n",
    "for f in all_svg:\n",
    "    cat = find_category_for_path(f)\n",
    "    if not cat: continue\n",
    "    p = web_path(cat, f.name)\n",
    "    path_map.setdefault(p, p)  # identity\n",
    "\n",
    "# === Update insights.json ===\n",
    "\n",
    "def to_web_path_any(chart_path: str) -> str:\n",
    "    \"\"\"Convert any absolute/repo path to /charts/<...> web path (best effort).\"\"\"\n",
    "    if not chart_path:\n",
    "        return chart_path\n",
    "    cp = chart_path\n",
    "    if cp.startswith(\"/charts/\"):\n",
    "        return cp\n",
    "    m = re.search(r\"/public/(charts/.*)$\", cp)\n",
    "    if m: return \"/\" + m.group(1)\n",
    "    m = re.search(r\"(?:^|/)(charts/.*)$\", cp)\n",
    "    if m: return \"/\" + m.group(1)\n",
    "    # nothing matched; keep as-is\n",
    "    return cp\n",
    "\n",
    "insights = json.loads(INSIGHTS_JSON.read_text(encoding=\"utf-8\"))\n",
    "if not isinstance(insights, list):\n",
    "    sys.exit(\"insights.json is not a list\")\n",
    "\n",
    "updated = 0\n",
    "fixed_format = 0\n",
    "\n",
    "for ins in insights:\n",
    "    old_cp_raw = ins.get(\"chartPath\",\"\")\n",
    "    norm_old_web = to_web_path_any(old_cp_raw)\n",
    "\n",
    "    # If we reformatted (e.g., removed absolute path), note it\n",
    "    if norm_old_web != old_cp_raw:\n",
    "        fixed_format += 1\n",
    "\n",
    "    # If we renamed, swap to new path; else keep normalized/formatted\n",
    "    new_cp = path_map.get(norm_old_web, norm_old_web)\n",
    "\n",
    "    if ins.get(\"chartPath\") != new_cp:\n",
    "        ins[\"chartPath\"] = new_cp\n",
    "        updated += 1\n",
    "\n",
    "# sort by date (dd-mm-YYYY) and re-id\n",
    "def sort_key(ins):\n",
    "    try:\n",
    "        return datetime.strptime(ins.get(\"date\",\"01-01-1900\"), \"%d-%m-%Y\")\n",
    "    except Exception:\n",
    "        return datetime(1900,1,1)\n",
    "\n",
    "insights.sort(key=sort_key)\n",
    "for i, ins in enumerate(insights, 1):\n",
    "    ins[\"id\"] = i\n",
    "\n",
    "print(f\"üß© insights.json paths updated: {updated} (reformatted: {fixed_format})\")\n",
    "\n",
    "if APPLY_CHANGES:\n",
    "    # backup then write\n",
    "    backup = INSIGHTS_JSON.with_suffix(\".json.bak-slugify\")\n",
    "    backup.write_text(INSIGHTS_JSON.read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n",
    "    INSIGHTS_JSON.write_text(json.dumps(insights, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    print(f\"üõü Backup: {backup}\")\n",
    "    print(f\"üíæ Updated: {INSIGHTS_JSON}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Dry-run: set APPLY_CHANGES = True to write insights.json.\")\n",
    "\n",
    "print(\"\\n‚úÖ NEXT:\")\n",
    "print(\"1) Set APPLY_CHANGES = True and re-run to apply changes.\")\n",
    "print(\"2) git add -A && git commit -m 'Slugify charts + update insights paths' && git pull --rebase && git push\")\n",
    "print(\"3) Redeploy; filenames are now ASCII-hyphen and paths are web-safe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9963b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
